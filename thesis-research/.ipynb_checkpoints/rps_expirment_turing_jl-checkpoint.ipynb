{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "using Turing, StatsPlots, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent (generic function with 6 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare our Turing model.\n",
    "@model function agent(opponent_agent, my_action, opponent_action, depth=0, discrete_sampler = PG, discrete_sampler_hyper_param=10, num_of_iterations=10)\n",
    "    if depth > 0 \n",
    "        opp_action_chain = sample(opponent_agent(agent, opponent_action, my_action, depth-1), discrete_sampler(discrete_sampler_hyper_param), num_of_iterations, progress=false);\n",
    "        opp_alpha_1 = mean(opp_action_chain[:\"alpha[1]\"])\n",
    "        opp_alpha_2 = mean(opp_action_chain[:\"alpha[2]\"])\n",
    "        opp_alpha_3 = 1 - opp_alpha_1 - opp_alpha_2\n",
    "        alpha ~ Dirichlet([opp_alpha_3, opp_alpha_1 , opp_alpha_2])\n",
    "    else\n",
    "        # Our prior belief about the probability of RPS.\n",
    "        alpha ~ Dirichlet(ones(3))\n",
    "    end\n",
    "    my_action ~ Categorical(vec(alpha))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model\n",
    "1) prior on opponents <br>\n",
    "2) history <br>\n",
    "3) observation - history + prior => postrior <br> \n",
    "4) counter policy - 1) beating the next round 2) confuse the opponent (noise) <br>\n",
    "5) depth > 0 -> no history <br>\n",
    "6) sample action from the counter policy<br>\n",
    "7) optimal noise parameter <br>\n",
    "8) implment Bob and Alice <br>\n",
    "9) conditioning as rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_counter_policy (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_counter_policy(opp_alpha_1, opp_alpha_2, opp_alpha_3)\n",
    "    normalize_factor = opp_alpha_1 + opp_alpha_2 + opp_alpha_3\n",
    "    println([opp_alpha_3 / normalize_factor, opp_alpha_1 / normalize_factor, opp_alpha_2 / normalize_factor])\n",
    "    return [opp_alpha_3 / normalize_factor, opp_alpha_1 / normalize_factor, opp_alpha_2 / normalize_factor]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_distribution_from_history (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_distribution_from_history(actions_history)\n",
    "    count = Dict(\"1\" => 1, \"2\" => 1, \"3\" => 1)\n",
    "    for i in 1:(length(actions_history)-1)\n",
    "        opponent_action = actions_history[i]\n",
    "        count[opponent_action] = count[opponent_action] + 1\n",
    "    end\n",
    "    return [v for (k,v) in count]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent (generic function with 5 methods)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function agent(opponent_agent, my_history, opponent_history, depth = 0, discrete_sampler = PG, discrete_sampler_hyper_param=1, num_of_iterations=1)\n",
    "        if depth == 0\n",
    "            opponent_history_distribution = compute_distribution_from_history(opponent_history)\n",
    "            opp_alpha_1, opp_alpha_2, opp_alpha_3 = opponent_history_distribution\n",
    "            println(\"depth 0: 1: $opp_alpha_1, 2: $opp_alpha_2, 3: $opp_alpha_3\")\n",
    "        else\n",
    "            opp_action_chain = sample(opponent_agent(agent, opponent_history, my_history, depth-1), discrete_sampler(discrete_sampler_hyper_param), num_of_iterations, progress=true);\n",
    "            opp_alpha_1 = mean(opp_action_chain[:\"alpha[1]\"])\n",
    "            opp_alpha_2 = mean(opp_action_chain[:\"alpha[2]\"])\n",
    "            opp_alpha_3 = mean(opp_action_chain[:\"alpha[3]\"])\n",
    "            println(\"depth $depth: 1: $opp_alpha_1, 2: $opp_alpha_2, 3: $opp_alpha_3\")\n",
    "        end\n",
    "        counter_policy = compute_counter_policy(opp_alpha_1, opp_alpha_2, opp_alpha_3)\n",
    "        println(\"counter_policy: $counter_policy\")\n",
    "        my_history[length(my_history)] ~ Categorical(counter_policy)\n",
    "        println(\"ended computation\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent (generic function with 5 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare our Turing model.\n",
    "@model function agent(opponent_agent, my_history, opponent_history, depth=0, discrete_sampler = PG, discrete_sampler_hyper_param=1, num_of_iterations=1)\n",
    "    # Our prior belief about the probability of RPS.\n",
    "    alpha ~ Dirichlet(ones(3))\n",
    "    for i in 1:length(my_history)\n",
    "        println(\"$(i): depth: $(depth)\")\n",
    "        my_action = my_history[i]\n",
    "        opponent_action = opponent_history[i]\n",
    "        if depth > 0\n",
    "            println(\"before sample i is $(i) depth is $(depth)\")\n",
    "            # TODO - call only in the end\n",
    "            opp_action_chain = sample(opponent_agent(agent, opponent_history, my_history, depth-1), discrete_sampler(discrete_sampler_hyper_param), num_of_iterations, progress=true);\n",
    "            println(\"after sample i is $(i) depth is $(depth)\")\n",
    "            opp_alpha_1 = mean(opp_action_chain[:\"alpha[1]\"])\n",
    "            opp_alpha_2 = mean(opp_action_chain[:\"alpha[2]\"])\n",
    "            opp_alpha_3 = 1 - opp_alpha_1 - opp_alpha_2\n",
    "            counter_opponent_policy = [opp_alpha_3, opp_alpha_1 , opp_alpha_2]\n",
    "            counter_opponent_policy ~ Dirichlet(alpha)\n",
    "        end\n",
    "        println(\"ended i: $(i) observation depth is $(depth)\")\n",
    "        my_action ~ Categorical(alpha)\n",
    "    end\n",
    "    println(\"ended computation on $(length(my_history)) and $(length(opponent_history))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_action = 1\n",
    "opponent_action = 1\n",
    "my_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0: 1: 1, 2: 1, 3: 1\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "counter_policy: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "ended computation\n",
      "depth 0: 1: 1, 2: 1, 3: 1\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "counter_policy: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "ended computation\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: reducing over an empty collection is not allowed",
     "output_type": "error",
     "traceback": [
      "ArgumentError: reducing over an empty collection is not allowed",
      "",
      "Stacktrace:",
      " [1] _empty_reduce_error() at .\\reduce.jl:299",
      " [2] mapreduce_empty(::Function, ::Base.BottomRF{typeof(vcat)}, ::Type{T} where T) at .\\reduce.jl:342",
      " [3] reduce_empty(::Base.MappingRF{Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}},Base.BottomRF{typeof(vcat)}}, ::Type{Union{}}) at .\\reduce.jl:329",
      " [4] reduce_empty_iter at .\\reduce.jl:355 [inlined]",
      " [5] reduce_empty_iter at .\\reduce.jl:354 [inlined]",
      " [6] foldl_impl(::Base.MappingRF{Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}},Base.BottomRF{typeof(vcat)}}, ::NamedTuple{(),Tuple{}}, ::Tuple{}) at .\\reduce.jl:49",
      " [7] mapfoldl_impl(::Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}}, ::typeof(vcat), ::NamedTuple{(),Tuple{}}, ::Tuple{}) at .\\reduce.jl:44",
      " [8] mapfoldl(::Function, ::Function, ::Tuple{}; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at .\\reduce.jl:160",
      " [9] mapfoldl at .\\reduce.jl:160 [inlined]",
      " [10] #mapreduce#208 at .\\reduce.jl:287 [inlined]",
      " [11] mapreduce(::Function, ::Function, ::Tuple{}) at .\\reduce.jl:287",
      " [12] flatten_namedtuple(::NamedTuple{(),Tuple{}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:270",
      " [13] (::Turing.Inference.var\"#9#12\"{Array{Symbol,1}})(::Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:253",
      " [14] iterate at .\\generator.jl:47 [inlined]",
      " [15] _collect at .\\array.jl:699 [inlined]",
      " [16] collect_similar at .\\array.jl:628 [inlined]",
      " [17] map at .\\abstractarray.jl:2162 [inlined]",
      " [18] _params_to_array at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:252 [inlined]",
      " [19] bundle_samples(::Array{Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64},1}, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::DynamicPPL.VarInfo{NamedTuple{(),Tuple{}},Float64}, ::Type{Chains}; save_state::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:333",
      " [20] bundle_samples(::Array{Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64},1}, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::DynamicPPL.VarInfo{NamedTuple{(),Tuple{}},Float64}, ::Type{Chains}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:333",
      " [21] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:131",
      " [22] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [23] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [24] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [25] #18 at .\\In[30]:7 [inlined]",
      " [26] (::var\"#18#19\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext, ::typeof(agent), ::Array{Int64,1}, ::Array{Int64,1}, ::Int64, ::Type{T} where T, ::Int64, ::Int64) at .\\none:0",
      " [27] macro expansion at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:0 [inlined]",
      " [28] _evaluate(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:154",
      " [29] evaluate_threadunsafe(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:127",
      " [30] (::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}})(::Random._GLOBAL_RNG, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:92",
      " [31] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:126 [inlined]",
      " [32] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:125 [inlined]",
      " [33] step(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}; resume_from::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:73",
      " [34] step at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:66 [inlined]",
      " [35] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:78 [inlined]",
      " [36] macro expansion at C:\\Users\\tomer\\.julia\\packages\\ProgressLogging\\BBN0b\\src\\ProgressLogging.jl:328 [inlined]",
      " [37] (::AbstractMCMC.var\"#20#21\"{Bool,String,Nothing,Int64,Int64,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},Random._GLOBAL_RNG,DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}},DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}},Int64,Int64})() at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:11",
      " [38] with_logstate(::Function, ::Any) at .\\logging.jl:408",
      " [39] with_logger at .\\logging.jl:514 [inlined]",
      " [40] with_progresslogger(::Function, ::Module, ::Base.CoreLogging.SimpleLogger) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:34",
      " [41] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:10 [inlined]",
      " [42] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:76",
      " [43] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [44] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [45] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [46] top-level scope at In[34]:1",
      " [47] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "chain = sample(agent(agent, [my_action], [opponent_action], my_depth), PG(1), 1 , progress = true)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maximum_likelihood_action (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function maximum_likelihood_action(list_of_pairs)\n",
    "    max_key = -1\n",
    "    max_value = -1\n",
    "    for element in list_of_pairs\n",
    "        key = element[1]\n",
    "        value = element[2]\n",
    "        if value > max_value\n",
    "            max_value = value\n",
    "            max_key = key\n",
    "        end\n",
    "    end\n",
    "    println(\"maximum likelihood is $((max_key, max_value))\")\n",
    "    return (max_key, max_value)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "move (generic function with 2 methods)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function move(agent, other_agent, my_history, other_agent_history, my_depth=1)\n",
    "    other_agent_history = length(other_agent_history) > 0 ? other_agent_history : [1]\n",
    "    my_history = length(my_history) > 0 ? my_history : [1]\n",
    "    chain = sample(agent(other_agent, my_history, other_agent_history, my_depth), PG(1), 1, progress = false)\n",
    "    println(\"chain computation is ended\")\n",
    "    alpha_1 = (1, mean(chain[:\"alpha[1]\"]))\n",
    "    alpha_2 = (2, mean(chain[:\"alpha[2]\"]))\n",
    "    alpha_3 = (3, 1 - alpha_1[2] - alpha_2[2])\n",
    "    return maximum_likelihood_action([alpha_1, alpha_2, alpha_3])[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: depth: 1\n",
      "before sample i is 1 depth is 1\n",
      "1: depth: 0\n",
      "ended i: 1 observation depth is 0\n",
      "ended computation on 1 and 1\n",
      "1: depth: 0\n",
      "ended i: 1 observation depth is 0\n",
      "ended computation on 1 and 1\n",
      "after sample i is 1 depth is 1\n",
      "ended i: 1 observation depth is 1\n",
      "ended computation on 1 and 1\n",
      "1: depth: 1\n",
      "before sample i is 1 depth is 1\n",
      "1: depth: 0\n",
      "ended i: 1 observation depth is 0\n",
      "ended computation on 1 and 1\n",
      "1: depth: 0\n",
      "ended i: 1 observation depth is 0\n",
      "ended computation on 1 and 1\n",
      "after sample i is 1 depth is 1\n",
      "ended i: 1 observation depth is 1\n",
      "ended computation on 1 and 1\n",
      "chain computation is ended\n",
      "maximum likelihood is (3, 0.9666186395714202)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move(agent, agent, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function game()\n",
    "    first_player = agent\n",
    "    second_player = agent\n",
    "    num_of_simulations = 10\n",
    "    first_player_history = []\n",
    "    second_player_history = []\n",
    "    first_player_depth = 1\n",
    "    second_player_depth = 0\n",
    "    for i in 1:num_of_simulations\n",
    "        m1 = move(first_player, second_player, first_player_history, second_player_history, first_player_depth)\n",
    "        println(\"player1 choose $m1\")\n",
    "        push!(first_player_history, m1)\n",
    "        m2 = move(second_player, first_player, second_player_history, first_player_history, second_player_depth)\n",
    "        println(\"player2 choose $m2\")\n",
    "        push!(second_player_history, m2)\n",
    "        println(\"in simulation $i first player chose $m1 second player chose $m2\")\n",
    "    end\n",
    "    return first_player_history, second_player_history\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 0: 1: 1, 2: 1, 3: 1\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "counter_policy: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "ended computation\n",
      "depth 0: 1: 1, 2: 1, 3: 1\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "counter_policy: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "ended computation\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: reducing over an empty collection is not allowed",
     "output_type": "error",
     "traceback": [
      "ArgumentError: reducing over an empty collection is not allowed",
      "",
      "Stacktrace:",
      " [1] _empty_reduce_error() at .\\reduce.jl:299",
      " [2] mapreduce_empty(::Function, ::Base.BottomRF{typeof(vcat)}, ::Type{T} where T) at .\\reduce.jl:342",
      " [3] reduce_empty(::Base.MappingRF{Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}},Base.BottomRF{typeof(vcat)}}, ::Type{Union{}}) at .\\reduce.jl:329",
      " [4] reduce_empty_iter at .\\reduce.jl:355 [inlined]",
      " [5] reduce_empty_iter at .\\reduce.jl:354 [inlined]",
      " [6] foldl_impl(::Base.MappingRF{Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}},Base.BottomRF{typeof(vcat)}}, ::NamedTuple{(),Tuple{}}, ::Tuple{}) at .\\reduce.jl:49",
      " [7] mapfoldl_impl(::Turing.Inference.var\"#15#19\"{NamedTuple{(),Tuple{}}}, ::typeof(vcat), ::NamedTuple{(),Tuple{}}, ::Tuple{}) at .\\reduce.jl:44",
      " [8] mapfoldl(::Function, ::Function, ::Tuple{}; kw::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at .\\reduce.jl:160",
      " [9] mapfoldl at .\\reduce.jl:160 [inlined]",
      " [10] #mapreduce#208 at .\\reduce.jl:287 [inlined]",
      " [11] mapreduce(::Function, ::Function, ::Tuple{}) at .\\reduce.jl:287",
      " [12] flatten_namedtuple(::NamedTuple{(),Tuple{}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:270",
      " [13] (::Turing.Inference.var\"#9#12\"{Array{Symbol,1}})(::Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:253",
      " [14] iterate at .\\generator.jl:47 [inlined]",
      " [15] _collect at .\\array.jl:699 [inlined]",
      " [16] collect_similar at .\\array.jl:628 [inlined]",
      " [17] map at .\\abstractarray.jl:2162 [inlined]",
      " [18] _params_to_array at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:252 [inlined]",
      " [19] bundle_samples(::Array{Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64},1}, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::DynamicPPL.VarInfo{NamedTuple{(),Tuple{}},Float64}, ::Type{Chains}; save_state::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:333",
      " [20] bundle_samples(::Array{Turing.Inference.PGTransition{NamedTuple{(),Tuple{}},Float64},1}, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::DynamicPPL.VarInfo{NamedTuple{(),Tuple{}},Float64}, ::Type{Chains}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:333",
      " [21] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:131",
      " [22] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [23] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [24] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [25] #18 at .\\In[30]:7 [inlined]",
      " [26] (::var\"#18#19\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext, ::typeof(agent), ::Array{Int64,1}, ::Array{Int64,1}, ::Int64, ::Type{T} where T, ::Int64, ::Int64) at .\\none:0",
      " [27] macro expansion at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:0 [inlined]",
      " [28] _evaluate(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:154",
      " [29] evaluate_threadunsafe(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:127",
      " [30] (::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}})(::Random._GLOBAL_RNG, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:92",
      " [31] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:126 [inlined]",
      " [32] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:125 [inlined]",
      " [33] step(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}; resume_from::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:73",
      " [34] step at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:66 [inlined]",
      " [35] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:78 [inlined]",
      " [36] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:15 [inlined]",
      " [37] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:76",
      " [38] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#18#19\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [39] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [40] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [41] move(::typeof(agent), ::Function, ::Array{Any,1}, ::Array{Any,1}, ::Int64) at .\\In[16]:4",
      " [42] game() at .\\In[17]:10",
      " [43] top-level scope at In[31]:1",
      " [44] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
