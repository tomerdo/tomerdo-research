{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook presents an expriment of Theory Of Mind on Rock Paper Scissors\n",
    "### The goal is to research and devlop a method for generic multi-agent games using Theory of Mind modeling.\n",
    "### We will introduce the tradeoff between choosing optimal move and staying unpredictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "using Turing, StatsPlots, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computer_counter_policy\n",
    "Given infered information about the opponent.<br>\n",
    "Decide how to exploit it.<br>\n",
    "In the future we will optimize those parameters, to make the agent's move less predictible <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different counter policy computing.\n",
    "not optimal! will be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given history we want to know the distributin of the moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core of the notebook\n",
    "### Modeling Theory of Mind in Rock Paper Sciors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model of agent as universal Probalistic Model\n",
    "### gets some parmeters:\n",
    "<ul>\n",
    "    <li> opponent agent - representation of our belief on the opponent model (Turing.jl model)\n",
    "    <li> my history - list of all moves this player done (At this point unused)\n",
    "    <li> opponent history - list of all moves the opponent done, used to estimate a prior on the moves\n",
    "    <li> depth - the depth we want the agent will dive modeling the mind of opponent agent\n",
    "</ul>        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p_deceive = 0.5\n",
    "\n",
    "def best_move(opp_move):\n",
    "    best_moves = {1: 2, 2:3, 3:1}\n",
    "    move = best_moves[opp_move]\n",
    "    deceive ~ Bernoulli(p_deceive)\n",
    "    if deceive:\n",
    "        move = opp_move\n",
    "    return move\n",
    "  \n",
    "if depth == 0:\n",
    "    beta_opp ~ Dirichlet(1, 1, 1)\n",
    "    for opp_move in opp_history:\n",
    "        opp_move ~ Categorical(beta_opp) # observe\n",
    "    next_opp_move ~ Categorical(beta_opp) # sample\n",
    "else:\n",
    "    next_opp_move = sample(agent(depth=n-1)) # if you use MH - you need to burn samples in the chain first\n",
    "move = best_move(next_opp_move)\n",
    "return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best_move (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function best_move(opp_move)\n",
    "    best_moves = Dict(1 => 2, 2 => 3, 3 => 1)\n",
    "    move = best_moves[opp_move]\n",
    "    println(move)\n",
    "#     p_deceive = 0.001\n",
    "#     print(p_deceive)\n",
    "#     deceive ~ Bernoulli(p_deceive)\n",
    "#     print(deceive)\n",
    "#     if deceive\n",
    "#         move = opp_move\n",
    "#     end\n",
    "    return move\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agent (generic function with 5 methods)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function agent(opponent_agent, my_history, opponent_history, depth = 1, discrete_sampler = PG, discrete_sampler_hyper_param=1, num_of_iterations=1)\n",
    "    if depth == 0\n",
    "#         println(\"in depth 0\")\n",
    "        beta_opp ~ Dirichlet([1, 1, 1])\n",
    "#         println(\"length is \", length(opponent_history))\n",
    "        for opp_move in opponent_history\n",
    "            opp_move ~ Categorical(beta_opp) # observe\n",
    "        end\n",
    "    next_opp_move ~ Categorical(beta_opp) # sample\n",
    "#     println(\"next opp move is  \", next_opp_move)\n",
    "    else\n",
    "        opponent_model = opponent_agent(agent, opponent_history, my_history, depth-1)\n",
    "#         print(\"before sampling\")\n",
    "        next_opp_move_chain  = sample(opponent_model, discrete_sampler(discrete_sampler_hyper_param), num_of_iterations, progress=true); # if you use MH - you need to burn samples in the chain first\n",
    "        result = generated_quantities(opponent_model, next_opp_move_chain)\n",
    "#         print(\"result is \" , display(result))\n",
    "        # last sample\n",
    "#         println(\"chain is ready and it is \", display(next_opp_move_chain))\n",
    "#         println(\"result is ready and it is \", result)\n",
    "        next_opp_move_from_chain = last(result)\n",
    "        next_opp_move ~ Dirac(next_opp_move_from_chain)\n",
    "#         println(\"next opp is \" ,next_opp_move)\n",
    "    end\n",
    "    move = best_move(next_opp_move)\n",
    "    println(\"move is \", move)\n",
    "    return move\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the infece is about the opponent model and not my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "move is "
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled)) at .\\task.jl:656",
      " [2] wait at .\\task.jl:713 [inlined]",
      " [3] uv_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:933",
      " [4] unsafe_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:1005",
      " [5] unsafe_write at .\\io.jl:337 [inlined]",
      " [6] write at .\\strings\\io.jl:183 [inlined]",
      " [7] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String) at .\\strings\\io.jl:185",
      " [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::Int64, ::Vararg{Any,N} where N) at .\\strings\\io.jl:46",
      " [9] println(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::Vararg{Any,N} where N) at .\\strings\\io.jl:73",
      " [10] println(::String, ::Int64) at .\\coreio.jl:4",
      " [11] #47 at .\\In[58]:25 [inlined]",
      " [12] (::var\"#47#48\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext, ::typeof(agent), ::Array{Int64,1}, ::Array{Int64,1}, ::Int64, ::Type{T} where T, ::Int64, ::Int64) at .\\none:0",
      " [13] macro expansion at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:0 [inlined]",
      " [14] _evaluate(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:154",
      " [15] evaluate_threadunsafe(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:127",
      " [16] (::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}})(::Random._GLOBAL_RNG, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:92",
      " [17] DynamicPPL.VarInfo(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:126",
      " [18] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:125 [inlined]",
      " [19] step(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}; resume_from::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:73",
      " [20] step at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:66 [inlined]",
      " [21] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:78 [inlined]",
      " [22] macro expansion at C:\\Users\\tomer\\.julia\\packages\\ProgressLogging\\BBN0b\\src\\ProgressLogging.jl:328 [inlined]",
      " [23] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:8 [inlined]",
      " [24] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:76",
      " [25] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [26] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [27] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [28] #47 at .\\In[58]:14 [inlined]",
      " [29] (::var\"#47#48\")(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext, ::typeof(agent), ::Array{Int64,1}, ::Array{Int64,1}, ::Int64, ::Type{T} where T, ::Int64, ::Int64) at .\\none:0",
      " [30] macro expansion at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:0 [inlined]",
      " [31] _evaluate(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:154",
      " [32] evaluate_threadunsafe(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:127",
      " [33] (::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}})(::Random._GLOBAL_RNG, ::DynamicPPL.VarInfo{DynamicPPL.Metadata{Dict{DynamicPPL.VarName,Int64},Array{Distribution,1},Array{DynamicPPL.VarName,1},Array{Real,1},Array{Set{DynamicPPL.Selector},1}},Float64}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\model.jl:92",
      " [34] DynamicPPL.VarInfo(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.SampleFromPrior, ::DynamicPPL.DefaultContext) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:126",
      " [35] VarInfo at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\varinfo.jl:125 [inlined]",
      " [36] step(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}; resume_from::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:73",
      " [37] step at C:\\Users\\tomer\\.julia\\packages\\DynamicPPL\\u14IH\\src\\sampler.jl:66 [inlined]",
      " [38] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:78 [inlined]",
      " [39] macro expansion at C:\\Users\\tomer\\.julia\\packages\\ProgressLogging\\BBN0b\\src\\ProgressLogging.jl:328 [inlined]",
      " [40] (::AbstractMCMC.var\"#20#21\"{Bool,String,Nothing,Int64,Int64,Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}},Random._GLOBAL_RNG,DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}},DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}},Int64,Int64})() at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:11",
      " [41] with_logstate(::Function, ::Any) at .\\logging.jl:408",
      " [42] with_logger at .\\logging.jl:514 [inlined]",
      " [43] with_progresslogger(::Function, ::Module, ::Base.CoreLogging.SimpleLogger) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:34",
      " [44] macro expansion at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\logging.jl:10 [inlined]",
      " [45] mcmcsample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type{T} where T, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\AbstractMCMC\\Nw3Wn\\src\\sample.jl:76",
      " [46] sample(::Random._GLOBAL_RNG, ::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::DynamicPPL.Sampler{PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}}, ::Int64; chain_type::Type{T} where T, resume_from::Nothing, progress::Bool, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:157",
      " [47] sample at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:156 [inlined]",
      " [48] #sample#2 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [49] sample at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:143 [inlined]",
      " [50] #sample#1 at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133 [inlined]",
      " [51] sample(::DynamicPPL.Model{var\"#47#48\",(:opponent_agent, :my_history, :opponent_history, :depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(:depth, :discrete_sampler, :discrete_sampler_hyper_param, :num_of_iterations),(),Tuple{typeof(agent),Array{Int64,1},Array{Int64,1},Int64,Type{PG},Int64,Int64},Tuple{Int64,Type{PG},Int64,Int64}}, ::PG{(),AdvancedPS.ResampleWithESSThreshold{typeof(AdvancedPS.resample_systematic),Float64}}, ::Int64) at C:\\Users\\tomer\\.julia\\packages\\Turing\\O1Pn0\\src\\inference\\Inference.jl:133",
      " [52] top-level scope at In[59]:2"
     ]
    }
   ],
   "source": [
    "m = agent(agent, ones(Int64, 10) , 2* ones(Int64, 10))\n",
    "chain = sample(m, PG(3), 3)\n",
    "display(chain)\n",
    "return_values = generated_quantities(m, chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple aux function that return the most common sample - majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_common (generic function with 1 method)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function most_common(samples)\n",
    "    count = Dict(1 => 0, 2 => 0, 3 => 0)\n",
    "    for i in 1:length(samples)\n",
    "        count[samples[i]] += 1\n",
    "    end\n",
    "    max_k, max_v = -1 , -1\n",
    "    for (k, v) in count\n",
    "        if v > max_v\n",
    "            max_k , max_v = k, v\n",
    "        end\n",
    "    end\n",
    "    return max_k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method is used for the simulation, each model make a move at the end of this function, as a result of reasoning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "move (generic function with 2 methods)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function move(agent, other_agent, my_history, other_agent_history, my_depth=1)\n",
    "    other_agent_history = length(other_agent_history) > 0 ? other_agent_history : [1]\n",
    "    my_history = length(my_history) > 0 ? my_history : [1]\n",
    "    my_history = Array{Int}(my_history)\n",
    "    other_agent_history = Array{Int}(other_agent_history)\n",
    "    chain = sample(agent(other_agent, my_history, other_agent_history, my_depth), PG(5), 5, progress = true)\n",
    "    return most_common(chain[:\"next_move\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move(agent, agent, [1, 2], [2 , 3])\n",
    "move(agent, agent, [1, 2, 3], [2 , 3, 2])\n",
    "move(agent, agent, [1, 2, 2, 1], [2 , 3, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game simulation , given two agent models , depth params, let them play num of simulation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game (generic function with 3 methods)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function game(first_player_depth = 1, second_player_depth = 1)\n",
    "    first_player = agent\n",
    "    second_player = agent\n",
    "    num_of_simulations = 100\n",
    "    first_player_history = []\n",
    "    second_player_history = []\n",
    "    for i in 1:num_of_simulations\n",
    "        m1 = move(first_player, second_player, first_player_history, second_player_history, first_player_depth)\n",
    "#         println(\"player1 choose $m1\")\n",
    "        push!(first_player_history, m1)\n",
    "        m2 = move(second_player, first_player, second_player_history, first_player_history, second_player_depth)\n",
    "#         println(\"player2 choose $m2\")\n",
    "        push!(second_player_history, m2)\n",
    "#         println(\"in simulation $i first player chose $m1 second player chose $m2\")\n",
    "    end\n",
    "    return first_player_history, second_player_history\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function score(history)\n",
    "    first_player_history, second_player_history = history\n",
    "    first_wins = 0\n",
    "    ties = 0\n",
    "    second_wins = 0\n",
    "    wins = Dict(1 => 3, 2 => 1, 3 => 2)\n",
    "    for i in 1:length(first_player_history)\n",
    "        if wins[first_player_history[i]] == second_player_history[i]\n",
    "            first_wins += 1\n",
    "        elseif wins[second_player_history[i]] == first_player_history[i]\n",
    "            second_wins += 1\n",
    "        else\n",
    "            ties += 1\n",
    "        end\n",
    "    end\n",
    "    return first_wins, ties, second_wins\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "display_score (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function display_score(score)\n",
    "    num_of_wins_first, num_of_ties, num_of_wins_second = score\n",
    "    println(\"first player won: $num_of_wins_first\")\n",
    "    println(\"second player won: $num_of_wins_second\") \n",
    "    println(\"ties: $num_of_ties\") \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both player plays without theory of mind - equivilent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first player won: 14\n",
      "second player won: 11\n",
      "ties: 75\n"
     ]
    }
   ],
   "source": [
    "display_score(score(game(0, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd player plays with one level of theory of mind -> 2nd wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first player won: 16\n",
      "second player won: 28\n",
      "ties: 56\n"
     ]
    }
   ],
   "source": [
    "display_score(score(game(0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st player plays with one level of theory of mind -> 1st wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first player won: 32\n",
      "second player won: 7\n",
      "ties: 61\n"
     ]
    }
   ],
   "source": [
    "display_score(score(game(1, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both players play with one level of theory of mind -> preety much equivelent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first player won: 24\n",
      "second player won: 23\n",
      "ties: 53\n"
     ]
    }
   ],
   "source": [
    "display_score(score(game(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
