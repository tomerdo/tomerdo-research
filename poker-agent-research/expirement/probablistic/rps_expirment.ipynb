{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RPS - Rock Paper Scissors Agent - using PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will show an expirment of RPS game simulation.\n",
    "I will use two players:\n",
    "<ol>\n",
    "    <li>Simple Player - playing according to Categorical seed (alpha vector)</li>\n",
    "    <li> Inferencing Player - models the opponent as a Probalistic Program and by observations trying to infer the latent alpha vector.<br>\n",
    "        Using this infered vector the player will try to exploit the simple player.<br>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pymc3 as pm\n",
    "import logging\n",
    "logger = logging.getLogger('pymc3')\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Player\n",
    "The simple player creates a categorical distribution (with dirichlet prior) and a given alpha vector and returns <num_of_samples> samples from this distirbution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smart Player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infercing Player, takes the toolset of MCMC infernce. Each round this player takes the moves of the simple players as observations, and uses the same Probabalistic Model to posterior inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPS Model\n",
    "Probabalistic Program, describes the decision process.<br>\n",
    "    $dir \\sim Dirichlet(\\alpha_1, \\alpha_2, \\alpha_3)$<br>\n",
    "    $Action \\sim Categorical(dir)$\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps_player_model(alpha=[1, 1, 1], observed=None):\n",
    "    with pm.Model() as model:\n",
    "        dirichlet = pm.Dirichlet('dirichlet', a=alpha)\n",
    "        phi = pm.Categorical('phi', p=dirichlet, observed=observed)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beats(i):\n",
    "    return (i + 1) % 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base class of all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def move(self, history):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaivePlayer(Player):\n",
    "    \"\"\"Naive player chooses a move according to fixed probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, id, p=[1, 1, 1]):\n",
    "        Player.__init__(self, id)\n",
    "        p = np.array(p)\n",
    "        p = p/sum(p)\n",
    "        self.p = p\n",
    "    \n",
    "    def move(self, history):\n",
    "        return np.argmax(sp.stats.multinomial.rvs(1, self.p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequentistPlayer(Player):\n",
    "    \"\"\"Frequentist player uses prior history \n",
    "    to choose a move\n",
    "    \"\"\"\n",
    "    def __init__(self, id, counts=None):\n",
    "        Player.__init__(self, id)\n",
    "        if counts is None:\n",
    "            counts = [1, 1, 1]\n",
    "        self.counts = counts\n",
    "    \n",
    "    def stats(self, history):\n",
    "        counts = self.counts[:]\n",
    "        for id, m in history:\n",
    "            if id != self.id:\n",
    "                counts[m] += 1\n",
    "        return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedFrequentistPlayer(FrequentistPlayer):\n",
    "    def __init__(self, id, counts=None):\n",
    "        FrequentistPlayer.__init__(self, id, counts)\n",
    "        \n",
    "    def move(self, history):\n",
    "        counts = self.stats(history)\n",
    "        return beats(np.argmax(counts))\n",
    "    \n",
    "# Example\n",
    "# ffp = FixedFrequentistPlayer(1)\n",
    "# print([ffp.move([(1, 1), (2, 1), (1, 0), (2, 1)]) for _ in range(10)])\n",
    "# print([ffp.move([(1, 1), (2, 2), (1, 0), (2, 1), (1, 2), (2, 2)]) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomFrequentistPlayer(FrequentistPlayer):\n",
    "    def __init__(self, id, counts=None):\n",
    "        FrequentistPlayer.__init__(self, id, counts)\n",
    "        \n",
    "    def move(self, history):\n",
    "        counts = self.stats(history)\n",
    "        return beats(np.argmax(sp.stats.multinomial.rvs(n=1, p=counts/sum(counts))))\n",
    "    \n",
    "# Example\n",
    "# rfp = RandomFrequentistPlayer(1)\n",
    "# print([rfp.move([(1, 1), (2, 1), (1, 0), (2, 1)]) for _ in range(10)])\n",
    "# print([rfp.move([(1, 1), (2, 2), (1, 0), (2, 1), (1, 2), (2, 2)]) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianPlayer(Player):\n",
    "    def __init__(self, id, alpha=None):\n",
    "        Player.__init__(self, id)\n",
    "        if alpha is None:\n",
    "            alpha = 1, 1, 1\n",
    "        self.alpha = np.array(alpha)\n",
    "        \n",
    "    def opponent_model(self, history):\n",
    "        pass\n",
    "    \n",
    "    def select_action(samples):\n",
    "        pass\n",
    "    \n",
    "    def infer(self, model):\n",
    "        with model:\n",
    "            trace = pm.sample(step=pm.Metropolis(), model=model, return_inferencedata=True, progressbar=False, cores=1)\n",
    "            return trace\n",
    "        \n",
    "    def sample_from_posterior(self, model, trace, theta_var):\n",
    "        with model:\n",
    "            posterior_pred = pm.sample_posterior_predictive(trace, progressbar=False)\n",
    "            return beats(self.select_action(posterior_pred[theta_var]))\n",
    "        \n",
    "    def opponent_history(self, history):\n",
    "        moves_history = []\n",
    "        for idx, move in history:\n",
    "            if idx != self.id:\n",
    "                moves_history.append(move)\n",
    "        return moves_history\n",
    "    \n",
    "    def move(self, history):\n",
    "        history = self.opponent_history(history)\n",
    "        opponent_model = self.opponent_model(history)\n",
    "        trace = self.infer(opponent_model)\n",
    "        return self.sample_from_posterior(opponent_model, trace, self.get_theta_var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalBaysianPlayer(BayesianPlayer):\n",
    "    def __init__(self, id, alpha = None):\n",
    "        BayesianPlayer.__init__(self, id, alpha)\n",
    "    \n",
    "    def opponent_model(self, history):\n",
    "        with pm.Model() as model:\n",
    "            dirichlet = pm.Dirichlet('dirichlet', a=self.alpha)\n",
    "            phi = pm.Categorical('phi', p=dirichlet, observed=history)\n",
    "            return model\n",
    "    \n",
    "    def get_theta_var(self):\n",
    "        return 'phi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedCategoricalBaysianPlayer(CategoricalBaysianPlayer):\n",
    "    def __init__(self, id, alpha = None):\n",
    "        CategoricalBaysianPlayer.__init__(self, id, alpha)\n",
    "    \n",
    "    def select_action(self, samples):\n",
    "        samples = samples.reshape(-1)\n",
    "        counts = [0, 0, 0]\n",
    "        # return most common sample\n",
    "        for m in samples:\n",
    "            counts[m] += 1\n",
    "        return np.argmax(np.array(counts))\n",
    "        \n",
    "# Example\n",
    "# fcbp = FixedCategoricalBaysianPlayer(1)\n",
    "# print([fcbp.move([(1, 1), (2, 1), (1, 0), (2, 1)]) for _ in range(10)])\n",
    "# print([fcbp.move([(1, 1), (2, 2), (1, 0), (2, 1), (1, 2), (2, 2)]) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCategoricalBaysianPlayer(CategoricalBaysianPlayer):\n",
    "    def __init__(self, id, alpha = None):\n",
    "        CategoricalBaysianPlayer.__init__(self, id, alpha)\n",
    "    \n",
    "    def select_action(self, samples):\n",
    "        samples = samples.reshape(-1)\n",
    "        counts = [0, 0, 0]\n",
    "        # return most common sample\n",
    "        for m in samples:\n",
    "            counts[m] += 1\n",
    "        counts = np.array(counts)\n",
    "        return np.argmax(sp.stats.multinomial.rvs(n=1, p=counts/sum(counts)))\n",
    "        \n",
    "# Example\n",
    "# rcbp = RandomCategoricalBaysianPlayer(1)\n",
    "# print([rcbp.move([(1, 1), (2, 1), (1, 0), (2, 1)]) for _ in range(10)])\n",
    "# print([rcbp.move([(1, 1), (2, 2), (1, 0), (2, 1), (1, 2), (2, 2)]) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCK = 0\n",
    "PAPER = 1\n",
    "SCISSORS = 2\n",
    "def score(m1, m2):\n",
    "    # ROCK < PAPER < SCISSORS < ROCK\n",
    "    if m1==m2:\n",
    "        return 0\n",
    "    score = -1\n",
    "    if m1 > m2:\n",
    "        m1, m2 = m2, m1\n",
    "        score = -score\n",
    "    if m2 - m1 == 2:\n",
    "        score = -score\n",
    "    return score\n",
    "\n",
    "def summerize_score(scores):\n",
    "    first_wins = scores.count(1)\n",
    "    ties = scores.count(0)\n",
    "    second_wins = scores.count(-1)\n",
    "    return first_wins, ties, second_wins\n",
    "\n",
    "def game(player1, player2, n=20):\n",
    "    # TODO play the game with two players\n",
    "    history = []\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        m1 = player1.move(history)\n",
    "        history.append([1, m1])\n",
    "        m2 = player2.move(history)\n",
    "        history.append([2, m2])\n",
    "        scores.append(score(m1, m2))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between random frequentist player and naive player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, -1, 0, 0, -1, 0, 1, 1, -1, 0, 1, -1, 1, 0, -1, 0, 1, -1, 0]\n",
      "first wins:6 ties: 8 second wins: 6\n"
     ]
    }
   ],
   "source": [
    "rfp = RandomFrequentistPlayer(1)\n",
    "nap = NaivePlayer(2)\n",
    "play_game_and_print_summery(rfp,nap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between categorical bayesian player and naive player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -1, 1, 0, 0, 0, 0, 1, -1, 0, 1, -1, -1, -1, 0, -1, 1, -1, 0, -1]\n",
      "first wins:5 ties: 7 second wins: 8\n"
     ]
    }
   ],
   "source": [
    "rcbp = RandomCategoricalBaysianPlayer(1)\n",
    "nap = NaivePlayer(2)\n",
    "play_game_and_print_summery(rcbp,nap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between random frequentist player and categorical baysian player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, -1, 0, -1, -1, 1, 0, 1, 0, 1, -1, -1, -1]\n",
      "first wins:3 ties: 11 second wins: 6\n"
     ]
    }
   ],
   "source": [
    "rfp = RandomFrequentistPlayer(1)\n",
    "rcbp = RandomCategoricalBaysianPlayer(2)\n",
    "play_game_and_print_summery(rfp,rcbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between random frequentist player and fixed frequentist player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 0, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, 0, 1, -1, 1, -1, -1]\n",
      "first wins:6 ties: 2 second wins: 12\n"
     ]
    }
   ],
   "source": [
    "rfp = RandomFrequentistPlayer(1)\n",
    "ffp = FixedFrequentistPlayer(2)\n",
    "play_game_and_print_summery(rfp,ffp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between fixed baysien player and naive player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, -1, 1, 0, 1, 0, 1, 0, 0, 1, 1, -1, -1, -1, 1, -1]\n",
      "first wins:8 ties: 7 second wins: 5\n"
     ]
    }
   ],
   "source": [
    "fcbp = FixedCategoricalBaysianPlayer(1)\n",
    "nap = NaivePlayer(2)\n",
    "play_game_and_print_summery(fcbp,nap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game between fixed baysien player and exploitable naive player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 1, -1, -1, -1, 0, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1]\n",
      "first wins:13 ties: 2 second wins: 5\n"
     ]
    }
   ],
   "source": [
    "fcbp = FixedCategoricalBaysianPlayer(1)\n",
    "nap = NaivePlayer(2, p=[5, 1, 1])\n",
    "play_game_and_print_summery(fcbp,nap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Infernce\n",
    "using PPL infernce - Metropolis Hasting Algorithm due to the fact that the distribution is discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model):\n",
    "    with model:\n",
    "        trace = pm.sample(step=pm.Metropolis(), model=model, return_inferencedata=True, progressbar=False)\n",
    "        return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Posterior Sampling\n",
    "sampling from the posterior and return the most common action at each stage<br>\n",
    "The smart player using this sampling to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_posterior(model, trace):\n",
    "    with model:\n",
    "        posterior_pred = pm.sample_posterior_predictive(trace, progressbar=False)\n",
    "        median_over_samples = np.median(posterior_pred['phi'], axis=0)\n",
    "        return median_over_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the model without observations\n",
    "The simple player using this sampling.<br> given alpha vector it's draw samples from the distribtuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_prior(model, num_of_samples):\n",
    "    with model:\n",
    "        samples = pm.sample_prior_predictive(num_of_samples)['phi']\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "In the expirement we will look at those two player playing. and will examine the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some aux function for RPS\n",
    "Rock Paper Scissors is popular game.\n",
    "With 3 Actions (Rock , Paper , Scissors) each action lose and wins exactly other action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beats(i):\n",
    "    return (i + 1) % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "\n",
    "class RPS(IntEnum):\n",
    "    ROCK = 0,\n",
    "    PAPER = 1,\n",
    "    SCISSORS = 2\n",
    "    \n",
    "def get_result(first_player, second_player):\n",
    "    if first_player == second_player:\n",
    "        return 0\n",
    "    elif (first_player == RPS.ROCK and second_player == RPS.SCISSORS) or (\n",
    "            first_player == RPS.PAPER and second_player == RPS.ROCK) or (\n",
    "            first_player == RPS.SCISSORS and second_player == RPS.PAPER):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator\n",
    "We run <num_of_simulations> simulations.<br>\n",
    "Each simulation the simple player plays number of actions from the Probalistic Distribution with alpha vector as parameter.<br>\n",
    "The Smart player infer about the observations of the previous round and suggest <num_of_samples> action.<br> The Simple player does the same with constant distribution and the simulator compare the results and update the number.<br>\n",
    "In the end we look at the expactation of each player to win and the ties.<br>\n",
    "We check if the smart player is realy \"smarter\" then the simple player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_with_latent_alpha(num_of_simulations=10, alpha=[1, 1, 1]):\n",
    "    total_smart_player_wins = 0\n",
    "    total_simple_player_wins = 0\n",
    "    total_ties = 0\n",
    "\n",
    "    simple_player_observation = []\n",
    "\n",
    "    for i in range(num_of_simulations):\n",
    "        # Learning phase\n",
    "        simple_player = rps_player_model(alpha=alpha)\n",
    "\n",
    "        if len(simple_player_observation) == 0:\n",
    "            simple_player_observations = sample_from_prior(simple_player, num_of_samples=10)\n",
    "\n",
    "        # gets a list of observed values and returns the distribution of probable action\n",
    "        smart_player = rps_player_model(observed=simple_player_observations)\n",
    "        trace = infer(smart_player)\n",
    "\n",
    "        smart_player_next_moves = sample_from_posterior(smart_player, trace)\n",
    "        smart_player_next_moves = list(map(beats, smart_player_next_moves))\n",
    "\n",
    "        # Evaluation phase\n",
    "        simple_player_next_moves = sample_from_prior(simple_player, num_of_samples=10)\n",
    "\n",
    "        smart_player_wins = 0\n",
    "        simple_player_wins = 0\n",
    "        ties = 0\n",
    "\n",
    "        for j in range(len(simple_player_next_moves)):\n",
    "            result = get_result(smart_player_next_moves[j], simple_player_next_moves[j])\n",
    "            if result > 0:\n",
    "                smart_player_wins += 1\n",
    "            elif result < 0:\n",
    "                simple_player_wins += 1\n",
    "            else:\n",
    "                ties += 1\n",
    "        total_smart_player_wins += smart_player_wins\n",
    "        total_simple_player_wins += simple_player_wins\n",
    "        total_ties += ties\n",
    "        print(f'in simulation {i}: wins: {smart_player_wins}, loses: {simple_player_wins}, ties: {ties}')\n",
    "    print(\n",
    "        f'For opponent\\'s alpha vector: {alpha} averages in all simulations is wins: {total_smart_player_wins / num_of_simulations} '\n",
    "        f' loses:{total_simple_player_wins / num_of_simulations} ties:{total_ties / num_of_simulations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expirements\n",
    "I will check the results of different alpha played by the simple player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha = [1, 10, 10] (playing less Rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dirichlet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b4b379acb4b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msimulate_with_latent_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-806217454c74>\u001b[0m in \u001b[0;36msimulate_with_latent_alpha\u001b[1;34m(num_of_simulations, alpha)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_simulations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Learning phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msimple_player\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrps_player_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_player_observation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5eb1219257ab>\u001b[0m in \u001b[0;36mrps_player_model\u001b[1;34m(alpha, observed)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mdirirchlet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDirichlet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dirichlet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'phi'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirichlet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dirichlet' is not defined"
     ]
    }
   ],
   "source": [
    "simulate_with_latent_alpha(alpha=[1, 10, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_with_latent_alpha(alpha=[10, 6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_with_latent_alpha(alpha=[1, 6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_with_latent_alpha(alpha=[1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_with_latent_alpha(alpha=[1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summery\n",
    "we can see from the expirments that the \"smart\" player able to exploit the simple opponent.<br> As the opponent is farther from complete random strategy we succeed to exploit it better<br> And when it plays complete random the smart player do the same and the results are even\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
